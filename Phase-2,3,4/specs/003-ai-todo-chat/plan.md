# Implementation Plan: Intelligent Todo Agent (Grok + MCP)

**Branch**: `003-ai-todo-chat` | **Date**: 2026-01-02 | **Spec**: [specs/003-ai-todo-chat/spec.md](spec.md)
**Input**: Feature specification from `/specs/003-ai-todo-chat/spec.md`

## Summary
Implements a stateless, AI-powered chat interface using xAI's Grok model (via OpenAI Agents SDK) and the Model Context Protocol (MCP). Users manage tasks via natural language, with the backend persisting conversation state and executing task operations through secure MCP tools.

## Technical Context

**Language/Version**: Python 3.10+ (Backend), TypeScript 5+ (Frontend)
**Primary Dependencies**: 
- Backend: `openai` (targeting Grok), `mcp`, `fastapi`, `sqlmodel`, `alembic`
- Frontend: `next`, `ai`, `better-auth`
**Storage**: Neon Serverless PostgreSQL
**Testing**: `pytest` (Backend), `jest`/`playwright` (Frontend)
**Target Platform**: Web (Next.js Frontend + FastAPI Backend)
**Project Type**: Full-stack Web Application
**Performance Goals**: Chat latency < 3s p95.
**Constraints**: Stateless architecture (messages persisted to DB), User Isolation (strict ID filtering).
**Scale/Scope**: Single feature integration within existing Todo App.

## Constitution Check

*GATE: Must pass before Phase 0 research. Re-check after Phase 1 design.*

- **Agentic Workflow**: ✅ Plan generated by Agent.
- **Intelligent Agentic Stack**: ✅ Next.js, FastAPI, OpenAI Agents SDK (Grok), MCP SDK, SQLModel, Better Auth.
- **MCP First**: ✅ All task ops (CRUD) exposed as MCP tools.
- **Stateless Chat**: ✅ DB persistence for every turn designed.
- **Grok Model Mandate**: ✅ `base_url` configured for `api.x.ai`.
- **Secure Data Isolation**: ✅ `user_id` scope enforced in MCP tools.

## Project Structure

### Documentation (this feature)

```text
specs/003-ai-todo-chat/
├── plan.md              # This file
├── research.md          # Technical decisions & Grok/MCP research
├── data-model.md        # DB Schema (Tasks, Conversations, Messages)
├── quickstart.md        # Setup guide
├── contracts/           # OpenAPI specs
│   └── openapi.yaml
└── tasks.md             # (To be generated)
```

### Source Code (repository root)

```text
backend/
├── src/
│   ├── api/
│   │   └── routes/
│   │       └── chat.py          # Chat endpoint
│   ├── core/
│   │   └── config.py            # Env vars (GROK_API_KEY)
│   ├── models/
│   │   ├── chat.py              # Conversation, Message models
│   │   └── task.py              # Task model (existing/updated)
│   ├── services/
│   │   ├── agent_service.py     # OpenAI Agent logic
│   │   └── mcp_server.py        # MCP Tool definitions
│   └── main.py                  # App entry point
└── tests/
    └── test_chat_agent.py

frontend/
├── src/
│   ├── app/
│   │   └── dashboard/
│   │       └── chat/            # Chat Page
│   │           └── page.tsx
│   ├── components/
│   │   └── chat/
│   │       ├── ChatInterface.tsx # Vercel AI SDK UI
│   │       └── MessageList.tsx
│   └── lib/
│       └── chat-api.ts
```

**Structure Decision**: Standard Full-stack split. Backend hosts the Agent and MCP tools. Frontend uses standard Next.js App Router.

## Complexity Tracking

| Violation | Why Needed | Simpler Alternative Rejected Because |
|-----------|------------|-------------------------------------|
| Custom MCP Server | Spec Requirement | Direct function calling is simpler but violates "Build MCP Server" mandate. |
| Stateless Persistence | Constitution | Session memory is easier but violates "Stateless Chat" principle. |
